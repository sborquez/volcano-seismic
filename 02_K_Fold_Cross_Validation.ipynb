{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da82df49",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><a href=\"https://github.com/sborquez/volcano-seismic_classifier\">Volcano-Seismic Classifier</a> - Automatic classification of seismic signals from Llaima volcano (Chile).</h1>\n",
    "\n",
    "<center>\n",
    "<br>\n",
    "<img align=\"center\" src=\"images/utfsm.png\" width=\"50%\"/>\n",
    "\n",
    "<h2 align=\"center\">K-Fold Cross-Validation</h2>\n",
    "</center>\n",
    "\n",
    "<center>\n",
    "<i> Notebook created by Sebasti치n B칩rquez G. - <a href=\"mailto://sebstian.borquez@sansano.usm.cl\">sebastian.borquez@sansano.usm.cl</a> - utfsm - Jul 2021.</i>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbc26f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "import models\n",
    "import performance\n",
    "\n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ee442d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb --upgrade -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5937542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['WANDB_MODE'] = 'online'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8224125d",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "\n",
    "* [K-Fold Cross-Validation](#crossvalidation)\n",
    "* [SeismicNet](#seismic)\n",
    "* [Multi-Resolution Convolutional Neural Network](#mrcnn)\n",
    "* [Time Series Transformer](#transformer)\n",
    "* [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21276c2d",
   "metadata": {},
   "source": [
    "<a id=\"crossvalidation\"><a/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1819463",
   "metadata": {},
   "source": [
    "# K-Fold Cross-Validation\n",
    "\n",
    "![Kfold](images/02/cross_validation.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adfa6d7",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67c45d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_fold(sweep_q, worker_q):\n",
    "    worker_data = worker_q.get()\n",
    "    run_name = \"{}-{}\".format(worker_data.sweep_run_name, worker_data.num)\n",
    "    config = worker_data.config\n",
    "    dataset_artifact_name = worker_data.dataset_artifact_name\n",
    "    with wandb.init(project=\"volcano-seismic\", group=worker_data.sweep_id, job_type=\"model-training\", name=run_name,\n",
    "                    config=config,tags=[\"test\"]) as run:    \n",
    "        # Model builder configuration\n",
    "        ########################################\n",
    "        model_hyperparameters = config[\"model_hyperparameters\"]\n",
    "        training_configuration = config[\"training_configuration\"]\n",
    "        evaluation_configuration = config[\"evaluation_configuration\"]\n",
    "        builder = models.builders.get(model_hyperparameters[\"builder\"])\n",
    "        hyper_parameters = dict(model_hyperparameters)\n",
    "        del hyper_parameters[\"builder\"]\n",
    "        # Training configuration\n",
    "        ########################################\n",
    "        epochs = training_configuration[\"epochs\"]\n",
    "        loss =  models.get_loss(**training_configuration[\"loss\"])\n",
    "        optimizer =  models.get_optimizer(**training_configuration[\"optimizer\"])\n",
    "        batch_size = training_configuration[\"batch_size\"]\n",
    "        verbosity = training_configuration[\"verbosity\"]\n",
    "        # Load Data\n",
    "        ########################################\n",
    "        labels = worker_data.labels\n",
    "        num_classes = worker_data.num_classes\n",
    "        # 九덢잺 declare which artifact we'll be using\n",
    "        dataset_artifact = run.use_artifact(dataset_artifact_name)\n",
    "        # 游닌 if need be, download the artifact\n",
    "        dataset = dataset_artifact.download()\n",
    "        X,y = data.read_dataset(dataset, name=\"processed\")\n",
    "        # Split folds\n",
    "        train_index = sklearn.utils.shuffle(worker_data.train_index) # I don't know why is not shuffle\n",
    "        X_train, y_train = X[train_index], y[train_index]\n",
    "        test_index = worker_data.test_index\n",
    "        X_test, y_test = X[test_index], y[test_index]\n",
    "        print('Num clases:', num_classes)\n",
    "        print('Labels:', labels, type(labels))\n",
    "        print('X_train shape:', X_train.shape)\n",
    "        print('y_train shape:', y_train.shape)\n",
    "        print('X_test shape:', X_test.shape)\n",
    "        print('y_test shape:', y_test.shape)\n",
    "        # Load Model\n",
    "        ########################################\n",
    "        model = builder(**hyper_parameters)\n",
    "        # Compile the model\n",
    "        model.compile(\n",
    "            loss=loss,\n",
    "            optimizer=optimizer,\n",
    "            metrics=['categorical_accuracy' if num_classes > 2 else 'binary_accuracy']\n",
    "        )\n",
    "        assert model.predict(2*np.random.random((batch_size,6000,1)) - 1).shape == (batch_size, num_classes), \"Incorrect output shape.\"\n",
    "        # Train fold\n",
    "        ########################################\n",
    "        print(f'Training for fold {worker_data.num+1} ...')\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                  epochs=epochs, verbose=verbosity, batch_size=batch_size,\n",
    "                  callbacks=[\n",
    "                      wandb.keras.WandbCallback(verbose=verbosity, labels=labels, save_weights_only=True),\n",
    "                      tf.keras.callbacks.EarlyStopping(patience=5)\n",
    "                  ]\n",
    "        )\n",
    "        # Evaluation\n",
    "        ########################################\n",
    "        # Evaluation configuration\n",
    "        metrics = evaluation_configuration[\"metrics\"]\n",
    "        plots = evaluation_configuration[\"plots\"]\n",
    "        top_k = evaluation_configuration[\"top_k\"]\n",
    "        # load best mode\n",
    "        best_model = model\n",
    "        best_model.load_weights(Path(run.dir)/\"model-best.h5\")\n",
    "        y_prob = best_model.predict(X_test)\n",
    "        y_test = y_test.argmax(axis=-1) if num_classes > 2 else y_test\n",
    "        model_metrics, model_metrics_tables = performance.get_metrics(y_test, y_prob, metrics=metrics, labels=labels, num_classes=num_classes, run_id=worker_data.num)\n",
    "        model_plots = performance.get_plots(X_test, y_test, y_prob, plots=plots, labels=labels, num_classes=num_classes)\n",
    "        model_highlights= performance.get_highlights(X_test, y_test, y_prob, test_index, labels, top_k=top_k)\n",
    "        # Log to WandB\n",
    "        ########################################\n",
    "        run.log(\n",
    "            dict(\n",
    "                **model_metrics,\n",
    "                **model_metrics_tables,\n",
    "                **model_plots,\n",
    "                **model_highlights\n",
    "            )\n",
    "        )\n",
    "        sweep_q.put(WorkerDoneData(\n",
    "            metrics=model_metrics,\n",
    "            X_test=X_test, y_test=y_test, y_prob=y_prob\n",
    "        ))\n",
    "        run.join()\n",
    "    print(f\"Worker {worker_data.num} finished\")\n",
    "    \n",
    "\n",
    "def k_fold_cross_validation(model_hyperparameters, training_configuration, evaluation_configuration, k=10, seed=None):\n",
    "    # K-fold Parameters\n",
    "    ########################################\n",
    "    num_folds = k\n",
    "    dataset_artifact_name = 'llaima-preprocessed-1d:latest'\n",
    "    labels = [\"lp\", \"tc\", \"tr\", \"vt\"] \n",
    "    num_classes = len(labels)\n",
    "    # Spin up workers before calling wandb.init()\n",
    "    ########################################\n",
    "    # Workers will be blocked on a queue waiting to start\n",
    "    sweep_q = multiprocessing.Queue()\n",
    "    workers = []\n",
    "    for num in range(num_folds):\n",
    "        q = multiprocessing.Queue()\n",
    "        p = multiprocessing.Process(\n",
    "            target=training_fold, kwargs=dict(sweep_q=sweep_q, worker_q=q)\n",
    "        )\n",
    "        p.start()\n",
    "        workers.append(Worker(queue=q, process=p))\n",
    "    # Setup Cross-Validation WandB Runs Group\n",
    "    ##########################################\n",
    "    config = {\n",
    "        \"model_hyperparameters\": model_hyperparameters,\n",
    "        \"training_configuration\": training_configuration,\n",
    "        \"evaluation_configuration\": evaluation_configuration,\n",
    "        \"seed\": seed\n",
    "    }\n",
    "    #sweep_run = wandb.init(project=\"volcano-seismic\", job_type=\"cross-validation\", config=config,tags=[\"test\"])\n",
    "    with wandb.init(project=\"volcano-seismic\", job_type=\"cross-validation\", config=config) as sweep_run:\n",
    "        sweep_id = sweep_run.id\n",
    "        project_url = sweep_run.get_project_url()\n",
    "        sweep_group_url = \"{}/groups/{}\".format(project_url, sweep_id)\n",
    "        sweep_run.notes = sweep_group_url\n",
    "        sweep_run.save()\n",
    "        sweep_run_name = sweep_run.name #or sweep_run.id or \"unknown\"\n",
    "        print(\"*\" * 40)\n",
    "        print(\"Sweep Group URL: \", sweep_group_url)\n",
    "        print(\"*\" * 40)  \n",
    "        # Load Data\n",
    "        ########################################\n",
    "        # declare which artifact we'll be using\n",
    "        dataset_artifact = sweep_run.use_artifact(dataset_artifact_name)\n",
    "        # 游닌 if need be, download the artifact\n",
    "        dataset = dataset_artifact.download()\n",
    "        X,y = data.read_dataset(dataset, name=\"processed\")\n",
    "        print('Num clases:', num_classes)\n",
    "        print('Labels:', labels)\n",
    "        print('X shape:', X.shape)\n",
    "        print('y shape:', y.shape)\n",
    "        # Split 10-Folds\n",
    "        ########################################\n",
    "        # Define the K-fold Cross Validator\n",
    "        evaluations = []\n",
    "        kfold = sklearn.model_selection.StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "        # K-fold Cross Validation model evaluation\n",
    "        for num, (train_index, test_index) in enumerate(kfold.split(X, y.argmax(axis=-1))):\n",
    "            print('------------------------------------------------------------------------')\n",
    "            print(f'Worker for fold {num+1} ...')\n",
    "            config = {\n",
    "                \"model_hyperparameters\" : model_hyperparameters,\n",
    "                \"training_configuration\": training_configuration,\n",
    "                \"evaluation_configuration\": evaluation_configuration,\n",
    "                \"fold\": num\n",
    "            }\n",
    "            config.update(sweep_run.config)\n",
    "            # start worker\n",
    "            worker = workers[num]\n",
    "            worker.queue.put(\n",
    "                WorkerInitData(\n",
    "                    sweep_id=sweep_id,\n",
    "                    num=num,\n",
    "                    sweep_run_name=sweep_run_name,\n",
    "                    config=config,\n",
    "                    dataset_artifact_name=dataset_artifact_name,\n",
    "                    train_index=train_index,\n",
    "                    test_index=test_index,\n",
    "                    labels=labels,\n",
    "                    num_classes=num_classes\n",
    "                )\n",
    "            )\n",
    "            #get metric from worker\n",
    "            result = sweep_q.get()\n",
    "            # log metric to sweep_run\n",
    "            evaluations.append(result.metrics)\n",
    "        # Table of fold metrics and mean/variance row\n",
    "        ########################################\n",
    "        # folds\n",
    "        metrics_df = pd.DataFrame(evaluations).reset_index().rename(columns={\"index\": \"id\"})\n",
    "        metrics_df[\"id\"] = metrics_df[\"id\"].apply(lambda f: f'fold {f}')\n",
    "        # mean\n",
    "        metrics_mean = metrics_df.mean()\n",
    "        metrics_mean[\"id\"] = \"mean\"\n",
    "        metrics_df = metrics_df.append(metrics_mean, ignore_index=True)\n",
    "        # std\n",
    "        metrics_std = metrics_df.std()\n",
    "        metrics_std[\"id\"] = \"std\"\n",
    "        metrics_df = metrics_df.append(metrics_std, ignore_index=True)\n",
    "        # Log Table, mean and variance of all metrics\n",
    "        ########################################\n",
    "        metrics_mean_dict = {f\"mean {m}\": v for m,v in metrics_mean.drop(labels=[\"id\"]).iteritems()}\n",
    "        metrics_std_dict = {f\"std {m}\": v for m,v in metrics_mean.drop(labels=[\"id\"]).iteritems()}\n",
    "        ## Log to WandB\n",
    "        sweep_run.log(dict(\n",
    "            evaluation = wandb.Table(dataframe=metrics_df),\n",
    "            **metrics_mean_dict,\n",
    "            **metrics_std_dict,\n",
    "        ))\n",
    "        # Wait for worker to finish \n",
    "        ########################################\n",
    "        #sweep_run.join()\n",
    "        for num in range(num_folds):\n",
    "            print(\"wainting\", num)\n",
    "            worker = workers[num]\n",
    "            worker.process.join()\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944d5b63",
   "metadata": {},
   "source": [
    "<a id=\"SeismicNet\"><a/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fb4766",
   "metadata": {},
   "source": [
    "# SeismicNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72ad4237",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hyperparameters = {\n",
    "    \"builder\": \"mlp_builder\",\n",
    "    \"input_shape\": (6000,1),\n",
    "    \"num_classes\":4,\n",
    "    \"layers_units\": [256, 128]\n",
    "}\n",
    "\n",
    "training_configuration = {\n",
    "    \"epochs\": 2,\n",
    "    \"batch_size\": 128,\n",
    "    \"verbosity\": 0,\n",
    "    \"loss\": {\n",
    "        \"name\": \"categorical_crossentropy\",\n",
    "        \"parameters\": {}\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"name\": \"adam\",\n",
    "        \"parameters\": {\n",
    "            \"learning_rate\": 0.001\n",
    "        }\n",
    "    },\n",
    "        \n",
    "}\n",
    "evaluation_configuration = {\n",
    "    \"metrics\": [\"overall_classification_metrics\", \"classification_metrics_by_class\"],\n",
    "    \"plots\": [\"pr\", \"cm\"],\n",
    "    \"top_k\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4966386",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metrics = k_fold_cross_validation(model_hyperparameters, training_configuration, evaluation_configuration, k=10, seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdc03dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ACC Macro</th>\n",
       "      <th>ERR Macro</th>\n",
       "      <th>PPV Macro</th>\n",
       "      <th>TNR Macro</th>\n",
       "      <th>TPR Macro</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>TP - lp</th>\n",
       "      <th>TP - tc</th>\n",
       "      <th>...</th>\n",
       "      <th>TPR - tr</th>\n",
       "      <th>TPR - vt</th>\n",
       "      <th>ACC - lp</th>\n",
       "      <th>ACC - tc</th>\n",
       "      <th>ACC - tr</th>\n",
       "      <th>ACC - vt</th>\n",
       "      <th>F1 - lp</th>\n",
       "      <th>F1 - tc</th>\n",
       "      <th>F1 - tr</th>\n",
       "      <th>F1 - vt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fold 0</td>\n",
       "      <td>0.846047</td>\n",
       "      <td>0.153953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875134</td>\n",
       "      <td>0.455930</td>\n",
       "      <td>0.411645</td>\n",
       "      <td>0.499641</td>\n",
       "      <td>643.0</td>\n",
       "      <td>587.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.803452</td>\n",
       "      <td>0.796214</td>\n",
       "      <td>0.869154</td>\n",
       "      <td>9.153675e-01</td>\n",
       "      <td>0.784625</td>\n",
       "      <td>0.762338</td>\n",
       "      <td>0.099617</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fold 1</td>\n",
       "      <td>0.808463</td>\n",
       "      <td>0.191537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.859604</td>\n",
       "      <td>0.475903</td>\n",
       "      <td>0.435525</td>\n",
       "      <td>0.422564</td>\n",
       "      <td>650.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.787862</td>\n",
       "      <td>0.724388</td>\n",
       "      <td>0.806236</td>\n",
       "      <td>9.153675e-01</td>\n",
       "      <td>0.773349</td>\n",
       "      <td>0.585774</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.827255</td>\n",
       "      <td>0.172745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.867369</td>\n",
       "      <td>0.465916</td>\n",
       "      <td>0.423585</td>\n",
       "      <td>0.461103</td>\n",
       "      <td>646.5</td>\n",
       "      <td>468.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.795657</td>\n",
       "      <td>0.760301</td>\n",
       "      <td>0.837695</td>\n",
       "      <td>9.153675e-01</td>\n",
       "      <td>0.778987</td>\n",
       "      <td>0.674056</td>\n",
       "      <td>0.241298</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>std</td>\n",
       "      <td>0.018792</td>\n",
       "      <td>0.018792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007765</td>\n",
       "      <td>0.009987</td>\n",
       "      <td>0.011940</td>\n",
       "      <td>0.038539</td>\n",
       "      <td>3.5</td>\n",
       "      <td>118.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>0.035913</td>\n",
       "      <td>0.031459</td>\n",
       "      <td>1.359740e-16</td>\n",
       "      <td>0.005638</td>\n",
       "      <td>0.088282</td>\n",
       "      <td>0.141681</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows 칑 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  ACC Macro  ERR Macro  PPV Macro  TNR Macro  TPR Macro  F1 Macro  \\\n",
       "0  fold 0   0.846047   0.153953        0.0   0.875134   0.455930  0.411645   \n",
       "1  fold 1   0.808463   0.191537        0.0   0.859604   0.475903  0.435525   \n",
       "2    mean   0.827255   0.172745        0.0   0.867369   0.465916  0.423585   \n",
       "3     std   0.018792   0.018792        0.0   0.007765   0.009987  0.011940   \n",
       "\n",
       "      Kappa  TP - lp  TP - tc  ...  TPR - tr  TPR - vt  ACC - lp  ACC - tc  \\\n",
       "0  0.499641    643.0    587.0  ...  0.053061       0.0  0.803452  0.796214   \n",
       "1  0.422564    650.0    350.0  ...  0.440816       0.0  0.787862  0.724388   \n",
       "2  0.461103    646.5    468.5  ...  0.246939       0.0  0.795657  0.760301   \n",
       "3  0.038539      3.5    118.5  ...  0.193878       0.0  0.007795  0.035913   \n",
       "\n",
       "   ACC - tr      ACC - vt   F1 - lp   F1 - tc   F1 - tr  F1 - vt  \n",
       "0  0.869154  9.153675e-01  0.784625  0.762338  0.099617      0.0  \n",
       "1  0.806236  9.153675e-01  0.773349  0.585774  0.382979      0.0  \n",
       "2  0.837695  9.153675e-01  0.778987  0.674056  0.241298      0.0  \n",
       "3  0.031459  1.359740e-16  0.005638  0.088282  0.141681      0.0  \n",
       "\n",
       "[4 rows x 40 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69c9298",
   "metadata": {},
   "source": [
    "<a id=\"references\"><a/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bdec7f",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* [1] In-depth comparison of deep artificial neural network architectures on seismic events classification\n",
    "* [2] Llaima volcano dataset: In-depth comparison of deep artificial neural network architectures on seismic events classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce5444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
